# Machine-Translation

#### Solving the task of machine translation (from English to Vietnamese) with a regular Seq2Seq network and a global attention, dot product Seq2Seq network. Both following the Encoder-Decoder architecture.
#### Preprocessed data courtesy of the [Stanford NLP group](https://nlp.stanford.edu/projects/nmt/).

&nbsp;

### Standard Seq2Seq (Encoder-Decoder architecture) network
---
<img src="https://user-images.githubusercontent.com/40379856/102872974-56f6de80-43f5-11eb-9ea3-afb7ffc81162.jpg" width="90%"></img>

### Global attention-based, dot product Seq2Seq (Encoder-Decoder architecture) network
---
<img src="https://user-images.githubusercontent.com/40379856/102872988-5b22fc00-43f5-11eb-8eb5-c96b5cde2efc.gif" width="90%"></img>
